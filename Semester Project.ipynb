{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Getting the data into Python, and cleaning it.\n",
    "- will need to write code to import and clean, then functionalize it.\n",
    "\n",
    "Steps to clean data:\n",
    "\n",
    "*Remaining balance:\n",
    "- need to remove $ and ,\n",
    "- convert to integer\n",
    "pandas already did it\n",
    "\n",
    "*location:\n",
    "city names contain misspellings and characters\n",
    "state names are not all abbreviated\n",
    "some zip codes have postal codes\n",
    "- start by assigning all blank values as missing  \n",
    "- pull only the first part of the zip into a new col\n",
    "- if original zip col is not missing look zip up in zippopotamus to return city and state, \n",
    "- if original zip is missing or blank, look up city and state\n",
    "- if city and state are missing, return missing\n",
    "\n",
    "Language:\n",
    "-correct language blanks to missing\n",
    "\n",
    "*DOB:\n",
    "-assign DOBs before today as NA\n",
    "\n",
    "Marital status:\n",
    "- assign blanks to missing\n",
    "\n",
    "*Gender:\n",
    "- assign blanks to missing\n",
    "\n",
    "*Race:\n",
    "- some values for white misspelled\n",
    "- some values for American Indian misspelled\n",
    "- if contains american indian, then American Indian or Alaska Native\n",
    " - if starts with W, then white\n",
    "- assign blanks to missing\n",
    "\n",
    "*Hispanic/Latino:\n",
    "- some values mispelled\n",
    "- non-hispanic or latino not consistent\n",
    "- some values no\n",
    "- assign blanks to missing\n",
    "- Everything that starts with no should be assigned to non-hispanic or latino\n",
    "- if doesn't start with no or is missing, decline to answer,  or non-hispanic, assign to Hispanic or Latino\n",
    "\n",
    "*Sexual orientation:\n",
    "- assign blanks and N/As to missing\n",
    "- assign decline to \"decline to answer\"\n",
    "- If it starts with st assign to straight\n",
    "\n",
    "*Insurance type:\n",
    "- if contains medicare or medicaid, assign to Medicare & Medicaid\n",
    "- if starts with un then uninsured\n",
    "- if missing or blank, assign missing\n",
    "\n",
    "Household size:\n",
    "- assign the row with 4602 to blank\n",
    "- assign missings to blank?\n",
    "\n",
    "*Household income:\n",
    "- remove $ - and , assign as integers\n",
    "- assign missings to blank\n",
    "pandas already did it\n",
    "\n",
    "*Distance round trip:\n",
    "- take only numbers, assign text to missing\n",
    "\n",
    "referral source:\n",
    "- assign blanks to missing\n",
    "\n",
    "*Amount:\n",
    " - take only numbers, remove $ - and ,\n",
    "- assign blanks to missing\n",
    "\n",
    "*payment method:\n",
    "only text, assign responses with only numbers to missing\n",
    "\n",
    "payable to:\n",
    "Surely I don't have to do anything with this\n",
    "\n",
    "*patient letter notified:\n",
    "- assign na, n/a, missing, and blanks to No\n",
    "- assign dates to Y\n",
    "\n",
    "Application signed:\n",
    "should be fine.\n",
    "\n",
    "other:\n",
    "make sure data types align with what's needed\n",
    "- use type \"object\" to handle numerical and non-numerical data?\n",
    "Bulleted cols need to be cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do:\n",
    "-cleaning for address using zipopotamus api\n",
    "-lesson 9 to guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<positron-console-cell-8>:46: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Missing' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID#</th>\n",
       "      <th>Grant Req Date</th>\n",
       "      <th>App Year</th>\n",
       "      <th>Remaining Balance</th>\n",
       "      <th>Request Status</th>\n",
       "      <th>Payment Submitted?</th>\n",
       "      <th>Reason - Pending/No</th>\n",
       "      <th>Pt City</th>\n",
       "      <th>Pt State</th>\n",
       "      <th>Pt Zip</th>\n",
       "      <th>Language</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>Sexual Orientation</th>\n",
       "      <th>Insurance Type</th>\n",
       "      <th>Household Size</th>\n",
       "      <th>Total Household Gross Monthly Income</th>\n",
       "      <th>Distance roundtrip/Tx</th>\n",
       "      <th>Referral Source</th>\n",
       "      <th>Referred By:</th>\n",
       "      <th>Type of Assistance (CLASS)</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Payable to:</th>\n",
       "      <th>Patient Letter Notified? (Directly/Indirectly through rep)</th>\n",
       "      <th>Application Signed?</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180001</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1180.00</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCS</td>\n",
       "      <td>Dr. Natarajan/Lily Salinas</td>\n",
       "      <td>Medical Supplies/Prescription Co-pay(s)</td>\n",
       "      <td>320</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190001</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1428.39</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCS</td>\n",
       "      <td>Pam Owen/Sheri Shannon\\n</td>\n",
       "      <td>Medical Supplies/Prescription Co-pay(s)</td>\n",
       "      <td>21.61</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190001</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1428.39</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCS</td>\n",
       "      <td>Teresa Pfister</td>\n",
       "      <td>Food/Groceries</td>\n",
       "      <td>50</td>\n",
       "      <td>GC</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190002</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCS</td>\n",
       "      <td>AG/Susan Keith</td>\n",
       "      <td>Food/Groceries</td>\n",
       "      <td>100</td>\n",
       "      <td>GC</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190003</td>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>1</td>\n",
       "      <td>1425.00</td>\n",
       "      <td>Approved</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCS</td>\n",
       "      <td>AG/Kristi McHugh</td>\n",
       "      <td>Medical Supplies/Prescription Co-pay(s)</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>No</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>240393</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>Pending</td>\n",
       "      <td>No</td>\n",
       "      <td>HS</td>\n",
       "      <td>Falls City</td>\n",
       "      <td>NE</td>\n",
       "      <td>68355</td>\n",
       "      <td>English</td>\n",
       "      <td>1960-09-23 00:00:00</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Uninsured</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>CPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas</td>\n",
       "      <td>500</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waiting on HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>240393</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>Pending</td>\n",
       "      <td>No</td>\n",
       "      <td>HS</td>\n",
       "      <td>Falls City</td>\n",
       "      <td>NE</td>\n",
       "      <td>68355</td>\n",
       "      <td>English</td>\n",
       "      <td>1960-09-23 00:00:00</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Uninsured</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>CPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Food/Groceries</td>\n",
       "      <td>500</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waiting on HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>240548</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>Pending</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>NE</td>\n",
       "      <td>68025</td>\n",
       "      <td>English</td>\n",
       "      <td>1962-04-03 00:00:00</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Private</td>\n",
       "      <td>2</td>\n",
       "      <td>2895</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NCS</td>\n",
       "      <td>ALISA SEIDLER</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>1068.56</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>250038</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>Pending</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hastings</td>\n",
       "      <td>NE</td>\n",
       "      <td>68901</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1980-10-02 00:00:00</td>\n",
       "      <td>Single</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Uninsured</td>\n",
       "      <td>2</td>\n",
       "      <td>918</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Morrison Cancer Center</td>\n",
       "      <td>Kellie Sterkel-SW</td>\n",
       "      <td>Housing</td>\n",
       "      <td>1500</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>250040</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>Pending</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hastings</td>\n",
       "      <td>NE</td>\n",
       "      <td>68901</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1980-10-02 00:00:00</td>\n",
       "      <td>Single</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Uninsured</td>\n",
       "      <td>2</td>\n",
       "      <td>918</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Morrison Cancer Center</td>\n",
       "      <td>Kellie Sterkel</td>\n",
       "      <td>Housing</td>\n",
       "      <td>1500</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2292 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient ID# Grant Req Date  App Year  ...  Patient Letter Notified? (Directly/Indirectly through rep) Application Signed?           Notes\n",
       "0          180001     2018-10-17         1  ...                                                 No                      Missing             NaN\n",
       "1          190001     2019-01-03         1  ...                                                 No                      Missing             NaN\n",
       "2          190001     2019-03-11         1  ...                                                 No                      Missing             NaN\n",
       "3          190002     2019-05-20         1  ...                                                 No                      Missing             NaN\n",
       "4          190003     2019-05-22         1  ...                                                 No                      Missing             NaN\n",
       "...           ...            ...       ...  ...                                                ...                          ...             ...\n",
       "2287       240393     2025-01-31         2  ...                                                 No                          NaN  Waiting on HS \n",
       "2288       240393     2025-01-31         2  ...                                                 No                          NaN  Waiting on HS \n",
       "2289       240548     2025-01-31         2  ...                                                 No                          NaN             NaN\n",
       "2290       250038     2025-01-31         1  ...                                                 No                          NaN             NaN\n",
       "2291       250040     2025-01-31         1  ...                                                 No                          NaN             NaN\n",
       "\n",
       "[2292 rows x 30 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def fetch_zip_info(zip_codes):\n",
    "    \"\"\"Fetch city and state info for zip codes.\"\"\"\n",
    "    zip_to_locale = {}\n",
    "    for zip_code in zip_codes:\n",
    "        try:\n",
    "            url = f\"https://api.zippopotam.us/us/{zip_code}\"\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                zip_data = response.json()\n",
    "                city = zip_data['places'][0]['place name']\n",
    "                state = zip_data['places'][0]['state abbreviation']\n",
    "                zip_to_locale[zip_code] = {'City': city, 'State': state}\n",
    "            else:\n",
    "                zip_to_locale[zip_code] = {'City': 'Unknown', 'State': 'Unknown'}\n",
    "        except Exception:\n",
    "            zip_to_locale[zip_code] = {'City': 'Error', 'State': 'Error'}\n",
    "    return zip_to_locale\n",
    "\n",
    "def clean_data(filepath, sheet_name=None):\n",
    "    \"\"\"Clean the service learning data.\"\"\"\n",
    "    today = pd.Timestamp.today()\n",
    "\n",
    "    # Read file (Excel or CSV)\n",
    "    if filepath.endswith('.xlsx'):\n",
    "        data = pd.read_excel(filepath, sheet_name=sheet_name)\n",
    "    elif filepath.endswith('.csv'):\n",
    "        data = pd.read_csv(filepath)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format: Only .csv or .xlsx allowed.\")\n",
    "\n",
    "    # Clean Zip, City, State\n",
    "    data['Pt Zip'] = data['Pt Zip'].replace([\"\", np.nan], \"Missing\")\n",
    "    data.loc[data['Pt Zip'] == \"Missing\", ['Pt City', 'Pt State']] = \"Missing\"\n",
    "\n",
    "    valid_zips = data[data['Pt Zip'] != \"Missing\"]['Pt Zip'].unique()\n",
    "    zip_to_locale = fetch_zip_info(valid_zips)\n",
    "\n",
    "    data['Pt City'] = data['Pt Zip'].apply(lambda z: zip_to_locale.get(z, {}).get('City', 'Missing') if z != 'Missing' else 'Missing')\n",
    "    data['Pt State'] = data['Pt Zip'].apply(lambda z: zip_to_locale.get(z, {}).get('State', 'Missing') if z != 'Missing' else 'Missing')\n",
    "\n",
    "    # Clean DOB\n",
    "    data['DOB'] = pd.to_datetime(data['DOB'], errors='coerce')\n",
    "    data.loc[data['DOB'] > today, 'DOB'] = \"Missing\"\n",
    "\n",
    "    # Clean Gender\n",
    "    data['Gender'] = data['Gender'].replace(r'^\\s*$', \"Missing\", regex=True)\n",
    "\n",
    "    # Clean Race\n",
    "    data['Race'] = data['Race'].astype(str).str.strip().str.lower()\n",
    "    data['Race'] = data['Race'].apply(lambda x: (\n",
    "        'American Indian or Alaska Native' if 'american indian' in x else\n",
    "        'White' if x.startswith('w') else\n",
    "        \"Missing\" if x in ['', 'nan'] else x.title()\n",
    "    ))\n",
    "\n",
    "    # Clean Hispanic/Latino\n",
    "    data['Hispanic/Latino'] = data['Hispanic/Latino'].astype(str).str.strip().str.lower()\n",
    "    data['Hispanic/Latino'] = data['Hispanic/Latino'].apply(lambda x: (\n",
    "        'Non-Hispanic or Latino' if x.startswith('no') else\n",
    "        'Hispanic or Latino' if not (x.startswith('no') or x in ['nan', '', 'missing', 'decline to answer', 'non-hispanic']) else\n",
    "        np.nan\n",
    "    ))\n",
    "\n",
    "    # Clean Sexual Orientation\n",
    "    data['Sexual Orientation'] = data['Sexual Orientation'].astype(str).str.strip().str.lower()\n",
    "    data['Sexual Orientation'] = data['Sexual Orientation'].apply(lambda x: (\n",
    "        'Decline to answer' if x == 'decline' else\n",
    "        'Straight' if x.startswith('st') else\n",
    "        np.nan if x in ['n/a', '', 'nan'] else x.title()\n",
    "    ))\n",
    "\n",
    "    # Clean Insurance Type\n",
    "    data['Insurance Type'] = data['Insurance Type'].astype(str).str.strip().str.lower()\n",
    "    data['Insurance Type'] = data['Insurance Type'].apply(lambda x: (\n",
    "        'Medicare & Medicaid' if 'medicare' in x or 'medicaid' in x else\n",
    "        'Uninsured' if x.startswith('un') else\n",
    "        'Missing' if x in ['', 'nan'] else\n",
    "        x.title()\n",
    "    ))\n",
    "\n",
    "    # Clean Distance roundtrip\n",
    "    data['Distance roundtrip/Tx'] = pd.to_numeric(\n",
    "        data['Distance roundtrip/Tx'].astype(str).str.extract(r'(\\d+\\.?\\d*)')[0],\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Clean Payment Method\n",
    "    data['Payment Method'] = data['Payment Method'].astype(str).str.strip()\n",
    "    data['Payment Method'] = data['Payment Method'].apply(\n",
    "        lambda x: x if x.isalpha() else np.nan\n",
    "    )\n",
    "\n",
    "    # Clean Patient Letter Notified\n",
    "    def letter_notified(val):\n",
    "        val = str(val).strip().lower()\n",
    "        if val in ['na', 'n/a', 'missing', '', 'nan']:\n",
    "            return 'No'\n",
    "        try:\n",
    "            pd.to_datetime(val)\n",
    "            return 'Y'\n",
    "        except:\n",
    "            return 'No'\n",
    "\n",
    "    data['Patient Letter Notified? (Directly/Indirectly through rep)'] = data['Patient Letter Notified? (Directly/Indirectly through rep)'].apply(letter_notified)\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    \"\"\"Entry point for GitHub Action or local run.\"\"\"\n",
    "    # Get the changed file from GitHub Action argument\n",
    "    input_file = sys.argv[1]\n",
    "    output_file = os.path.splitext(input_file)[0] + \"_CLEANED.csv\"\n",
    "\n",
    "    # Detect sheet_name only if Excel\n",
    "    sheet_name = \"PA Log Sheet\" if input_file.endswith(\".xlsx\") else None\n",
    "\n",
    "    cleaned_df = clean_data(input_file, sheet_name=sheet_name)\n",
    "    cleaned_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"✅ Cleaned {input_file} -> {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name: Clean New Data\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    paths:\n",
    "      - '**/*.csv'\n",
    "      - '**/*.xlsx'\n",
    "    branches:\n",
    "      - main  # or your main branch\n",
    "\n",
    "jobs:\n",
    "  clean-data:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "    - name: Checkout code\n",
    "      uses: actions/checkout@v4\n",
    "\n",
    "    - name: Set up Python\n",
    "      uses: actions/setup-python@v5\n",
    "      with:\n",
    "        python-version: '3.x'\n",
    "\n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        pip install pandas numpy requests openpyxl\n",
    "\n",
    "    - name: Detect changed file\n",
    "      id: detect_file\n",
    "      run: |\n",
    "        echo \"CHANGED_FILE=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep -E '\\.csv$|\\.xlsx$' | head -n 1)\" >> $GITHUB_ENV\n",
    "\n",
    "    - name: Run data cleaning script\n",
    "      run: |\n",
    "        python clean_data_script.py \"$CHANGED_FILE\"\n",
    "\n",
    "    - name: Commit cleaned data\n",
    "      run: |\n",
    "        git config --global user.name 'github-actions[bot]'\n",
    "        git config --global user.email 'github-actions[bot]@users.noreply.github.com'\n",
    "        git add *_CLEANED.csv\n",
    "        git commit -m \"Automated: Cleaned $CHANGED_FILE\"\n",
    "        git push\n",
    "      continue-on-error: true"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
